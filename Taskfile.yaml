version: '3'

vars:
  DOCKER_IMAGE_NAME: '{{.DOCKER_IMAGE_NAME | default "roucru/idp-blueprint"}}'
  DOCKER_IMAGE_TAG: '{{.DOCKER_IMAGE_TAG | default "latest"}}'
  DOCKER_IMAGE_TAG_MINIMAL: '{{.DOCKER_IMAGE_TAG_MINIMAL | default "minimal"}}'

  # Network Configuration
  LAN_IP:
    sh: ip route get 1.1.1.1 2>/dev/null | awk '{print $7; exit}' || echo "127.0.0.1"

  # Helm Chart Versions
  CILIUM_VERSION: '{{.CILIUM_VERSION | default "1.18.2"}}'
  CERT_MANAGER_VERSION: '{{.CERT_MANAGER_VERSION | default "v1.19.0"}}'
  PROMETHEUS_CRDS_VERSION: '{{.PROMETHEUS_CRDS_VERSION | default "77.14.0"}}'
  GATEWAY_API_VERSION: '{{.GATEWAY_API_VERSION | default "v1.2.1"}}'
  EXTERNAL_SECRETS_VERSION: '{{.EXTERNAL_SECRETS_VERSION | default "0.20.2"}}'
  VAULT_VERSION: '{{.VAULT_VERSION | default "0.31.0"}}'
  ARGOCD_VERSION: '{{.ARGOCD_VERSION | default "8.6.0"}}'

  # Operational Settings
  KUBECTL_TIMEOUT: '{{.KUBECTL_TIMEOUT | default "300s"}}'
  K3D_CONFIG: '{{.K3D_CONFIG | default "IT/k3d-cluster-cached.yaml"}}'
  REGISTRY_CACHE_PATH: '{{.REGISTRY_CACHE_PATH | default "$HOME/.k3d-registry"}}'

  # k3d NodePort Configuration
  NODEPORT_HTTP: '30080'
  NODEPORT_HTTPS: '30443'

  # ArgoCD Configuration
  ARGOCD_SYNC_TIMEOUT: '10m'
  ARGOCD_BACKOFF_DURATION: '10s'
  ARGOCD_BACKOFF_FACTOR: '2'
  ARGOCD_BACKOFF_MAX_DURATION: '10m'
  ARGOCD_RETRY_LIMIT: '10'

  # Gateway Timeouts
  GATEWAY_WAIT_TIMEOUT: '60s'

  # Password Configuration
  # Empty string = generate random
  # Defined value = use provided password
  ARGOCD_ADMIN_PASSWORD: '{{.ARGOCD_ADMIN_PASSWORD | default "argo"}}'
  GRAFANA_ADMIN_PASSWORD: '{{.GRAFANA_ADMIN_PASSWORD | default ""}}'
  SONARQUBE_ADMIN_PASSWORD: '{{.SONARQUBE_ADMIN_PASSWORD | default ""}}'
  SONARQUBE_MONITORING_PASSCODE: '{{.SONARQUBE_MONITORING_PASSCODE | default ""}}'

  # Docker Registry Configuration
  DOCKER_REGISTRY_URL: '{{.DOCKER_REGISTRY_URL | default "docker.io"}}'
  DOCKER_REGISTRY_USERNAME: '{{.DOCKER_REGISTRY_USERNAME | default ""}}'
  DOCKER_REGISTRY_PASSWORD: '{{.DOCKER_REGISTRY_PASSWORD | default ""}}'

tasks:
  deploy:
    desc: 'Deploy the entire IDP platform'
    cmds:
      - defer: echo '{{if .EXIT_CODE}}âš ï¸  Deployment failed! Run "task destroy" to clean up and retry.{{else}}Success ğŸ˜Œ{{end}}'
      # 1. Bootstrap Cluster
      - task: k3d:create
      - task: it:apply-namespaces
      - task: it:bootstrap
      - task: cilium:deploy
      # 2. Secrets & Certs Management
      - task: it:deploy-secret-and-certs
      - task: external-secrets:deploy
      # 3. Deploy GitOps Engine
      - task: argocd:deploy
      # 4. Deploy Gateway (requires cert-manager ClusterIssuer)
      - task: gateway:deploy
      # 5. Deploy Policy as Code Engine
      - task: policies:deploy
      # 6. Deploy Application Stacks for everything else
      - task: stacks:deploy # Everything else that's part of the IDP
      - exit 0

  deploy:nocache:
    desc: 'Deploy without registry cache (test slow pulls)'
    cmds:
      - task: deploy
        vars:
          K3D_CONFIG: IT/k3d-cluster.yaml

  destroy:
    desc: 'Remove all IDP related components and cluster'
    cmds:
      - k3d cluster delete idp-demo

  # Deploys
  # ------------------------------------------------------------------------------
  stacks:deploy:
    desc: 'Deploy all application stacks via ArgoCD ApplicationSets'
    deps:
      - observability:deploy
      - cicd:deploy
      - security:deploy

  policies:deploy:
    desc: 'Deploy the Kyverno Policy Engine and policies via ArgoCD'
    cmds:
      - kubectl apply -f Policies/app-kyverno.yaml

  observability:deploy:
    desc: 'Deploy the Observability Stack via ArgoCD'
    cmds:
      - kubectl apply -f K8s/observability/applicationset-observability.yaml

  cicd:deploy:
    desc: 'Deploy the CICD Stack via ArgoCD'
    cmds:
      - kubectl apply -f K8s/cicd/applicationset-cicd.yaml

  security:deploy:
    desc: 'Deploy the Security Stack via ArgoCD'
    cmds:
      - kubectl apply -f K8s/security/applicationset-security.yaml

  # K8s Setup
  # ------------------------------------------------------------------------------
  k3d:create:
    desc: 'Create a k3d cluster with 3 nodes'
    status:
      - k3d cluster list | grep -q "idp-demo"
    cmds:
      - k3d cluster create idp-demo -c {{.K3D_CONFIG}}

  it:bootstrap:
    desc: 'Bootstrap cluster prerequisites and preload images'
    deps:
      - cilium:preload
      - it:apply-serviceaccounts
      - it:apply-crds
      - it:apply-priorityclasses

  it:apply-namespaces:
    desc: 'Apply all IT bootstrap namespaces via Kustomize'
    cmds:
      - kustomize build IT/namespaces/ | kubectl apply -f -

  it:apply-serviceaccounts:
    desc: 'Apply all IT bootstrap ServiceAccounts via Kustomize'
    cmds:
      - kustomize build IT/serviceaccounts/ | kubectl apply -f -

  it:apply-crds:
    desc: 'Apply all CRDs required for the platform'
    deps:
      - it:apply-gateway-api-crds
      - it:apply-prometheus-crds

  it:apply-priorityclasses:
    desc: 'Apply PriorityClasses for pod scheduling'
    cmds:
      - kustomize build IT/priorityclasses/ | kubectl apply -f -

  it:apply-gateway-api-crds:
    desc: 'Apply Gateway API CRDs'
    cmds:
      - |
        GATEWAY_API_URL="https://github.com/kubernetes-sigs/gateway-api/releases/download/{{.GATEWAY_API_VERSION}}/standard-install.yaml"
        TEMP_FILE="/tmp/gateway-api-{{.GATEWAY_API_VERSION}}.yaml"
        if [ ! -f "$TEMP_FILE" ]; then
          curl -fsSL "$GATEWAY_API_URL" -o "$TEMP_FILE"
        fi
        kubectl apply -f "$TEMP_FILE"

  it:apply-prometheus-crds:
    desc: 'Apply Prometheus CRDs from the dedicated Helm chart'
    cmds:
      - |
        helm upgrade --install prometheus-crds prometheus-community/prometheus-operator-crds \
          --version 23.0.0 \
          --namespace kube-system \
          --hide-notes

  # Cilium
  # ------------------------------------------------------------------------------
  cilium:preload:
    desc: 'Pre-load Cilium image to Docker host'
    vars:
      CILIUM_IMAGE: 'quay.io/cilium/cilium:v{{.CILIUM_VERSION}}'
    cmds:
      - docker pull {{.CILIUM_IMAGE}}

  cilium:deploy:
    desc: 'Install Cilium as CNI'
    cmds:
      - |
        helm upgrade --install cilium cilium/cilium \
          --version {{.CILIUM_VERSION}} \
          --namespace kube-system \
          --values IT/cilium/cilium-values.yaml \
          --hide-notes
      - kubectl wait --for=condition=Ready pods -l k8s-app=cilium -n kube-system --timeout={{.KUBECTL_TIMEOUT}}

  # Infrastructure Parallel Deployment
  # ------------------------------------------------------------------------------
  it:deploy-secret-and-certs:
    desc: 'Deploy cert-manager and vault'
    deps:
      - cert-manager:deploy
      - vault:deploy

  # Cert Manager
  # ------------------------------------------------------------------------------
  cert-manager:deploy:
    desc: 'Deploy Cert-Manager to handle CA'
    cmds:
      - |
        helm upgrade --install cert-manager jetstack/cert-manager \
          --version {{.CERT_MANAGER_VERSION}} \
          --namespace cert-manager \
          --values IT/cert-manager/cert-manager-values.yaml \
          --hide-notes
      - kubectl wait --for=condition=Available deployment/cert-manager-webhook -n cert-manager --timeout={{.KUBECTL_TIMEOUT}}
      - task: it:cert-manager:apply-resources

  it:cert-manager:apply-resources:
    desc: 'Apply all Cert-Manager bootstrap resources via Kustomize'
    cmds:
      - kustomize build IT/cert-manager/ | kubectl apply -f -

  # Gateway API
  # ------------------------------------------------------------------------------
  gateway:deploy:
    desc: 'Deploy Gateway API Gateway resource'
    env:
      DNS_SUFFIX: '{{.LAN_IP | replace "." "-"}}.nip.io'
    cmds:
      # 1. Apply Gateway resources (triggers service creation)
      - kustomize build IT/gateway/ | envsubst | kubectl apply -f -
      # 2. Wait for the service to be created by Cilium
      - kubectl wait --for=jsonpath='{.status.addresses}' gateway/idp-gateway -n kube-system --timeout={{.GATEWAY_WAIT_TIMEOUT}} || echo "âš ï¸  Gateway service not ready yet, continuing..."
      - sleep 3
      # 3. Apply NodePort patch immediately while service is fresh
      - kubectl apply -f IT/gateway/patch/gateway-service-patch.yaml
      # 4. Verify patch was applied correctly
      - |
        HTTP_PORT=$(kubectl get svc cilium-gateway-idp-gateway -n kube-system -o jsonpath='{.spec.ports[?(@.name=="port-80")].nodePort}')
        HTTPS_PORT=$(kubectl get svc cilium-gateway-idp-gateway -n kube-system -o jsonpath='{.spec.ports[?(@.name=="port-443")].nodePort}')
        if [ "$HTTP_PORT" != "{{.NODEPORT_HTTP}}" ] || [ "$HTTPS_PORT" != "{{.NODEPORT_HTTPS}}" ]; then
          echo "âŒ NodePort patch failed! HTTP=$HTTP_PORT (expected {{.NODEPORT_HTTP}}), HTTPS=$HTTPS_PORT (expected {{.NODEPORT_HTTPS}})"
          exit 1
        fi
        echo "âœ… NodePorts verified: HTTP={{.NODEPORT_HTTP}}, HTTPS={{.NODEPORT_HTTPS}}"
      # 5. Now wait for Gateway to be fully programmed
      - kubectl wait --for=condition=Programmed gateway/idp-gateway -n kube-system --timeout={{.KUBECTL_TIMEOUT}}
      - echo "âœ… Gateway ready. Services available at:"
      - echo "   https://argocd.{{.LAN_IP | replace "." "-"}}.nip.io"
      - echo "   https://grafana.{{.LAN_IP | replace "." "-"}}.nip.io"
      - echo "   https://vault.{{.LAN_IP | replace "." "-"}}.nip.io"
      - echo "   https://sonarqube.{{.LAN_IP | replace "." "-"}}.nip.io"
      - echo "   https://workflows.{{.LAN_IP | replace "." "-"}}.nip.io"

  # ESO
  # ------------------------------------------------------------------------------
  external-secrets:deploy:
    desc: 'Install External Secrets Operator'
    cmds:
      - |
        helm upgrade --install external-secrets external-secrets/external-secrets \
          --version {{.EXTERNAL_SECRETS_VERSION}} \
          --namespace external-secrets-system \
          --values IT/external-secrets/eso-values.yaml \
          --hide-notes
      - kubectl wait --for=condition=available --timeout={{.KUBECTL_TIMEOUT}} deployment/external-secrets -n external-secrets-system
      - kubectl wait --for=condition=available --timeout={{.KUBECTL_TIMEOUT}} deployment/external-secrets-webhook -n external-secrets-system

  # Vault
  # ------------------------------------------------------------------------------
  vault:clean:
    desc: 'Clean Vault deployment'
    silent: true
    cmds:
      - cmd: helm uninstall vault -n vault-system
        ignore_error: true
      - kubectl delete pvc data-vault-0 -n vault-system --ignore-not-found=true
      - echo "âœ… Vault cleaned"

  vault:deploy:
    desc: 'Deploy HashiCorp Vault'
    cmds:
      - |
        helm upgrade --install vault hashicorp/vault \
          --version {{.VAULT_VERSION}} \
          --namespace vault-system \
          --values IT/vault/vault-values.yaml \
          --hide-notes
      - task: vault:init
      - task: vault:generate-secrets

  vault:init:
    desc: 'Initialize Vault and configure for ESO'
    cmds:
      - ./scripts/vault-init.sh

  vault:generate-secrets:
    desc: 'Generate initial secrets for all services using Vault'
    cmds:
      - ./scripts/vault-generate.sh secret/argocd/admin admin.password "{{.ARGOCD_ADMIN_PASSWORD}}" base64 bcrypt
      - ./scripts/vault-generate.sh secret/grafana/admin admin-password "{{.GRAFANA_ADMIN_PASSWORD}}" base64 none
      - ./scripts/vault-generate.sh secret/sonarqube/admin password "{{.SONARQUBE_ADMIN_PASSWORD}}" base64 none
      - ./scripts/vault-generate.sh secret/sonarqube/monitoring passcode "{{.SONARQUBE_MONITORING_PASSCODE}}" hex none
      - ./scripts/vault-generate.sh secret/docker/registry registry "{{.DOCKER_REGISTRY_URL}}" base64 none
      - ./scripts/vault-generate.sh secret/docker/registry username "{{.DOCKER_REGISTRY_USERNAME}}" base64 none
      - ./scripts/vault-generate.sh secret/docker/registry password "{{.DOCKER_REGISTRY_PASSWORD}}" base64 none

  it:eso:apply-resources:
    desc: 'Apply ESO SecretStores and ExternalSecrets'
    cmds:
      - kustomize build IT/external-secrets/ | kubectl apply -f -
      - kubectl wait --for=condition=Ready externalsecret/argocd-admin-password -n argocd --timeout=300s

  # ArgoCD
  # ------------------------------------------------------------------------------
  argocd:deploy:
    desc: 'Deploy ArgoCD GitOps Engine'
    cmds:
      - |
        helm upgrade --install argocd argo/argo-cd \
          --version {{.ARGOCD_VERSION}} \
          --namespace argocd \
          --values IT/argocd/argocd-values.yaml \
          --hide-notes
      - kubectl wait --for=condition=Available deployment/argocd-server -n argocd --timeout={{.KUBECTL_TIMEOUT}}
      - task: it:eso:apply-resources
      - kubectl apply -f IT/argocd/appproject-platform.yaml
      - kubectl apply -f IT/argocd/appproject-observability.yaml
      - kubectl apply -f IT/argocd/appproject-cicd.yaml
      - kubectl apply -f IT/argocd/appproject-security.yaml

  # Docker Image
  # ------------------------------------------------------------------------------
  image:build:
    desc: 'Build the Dev Container image (full variant)'
    env:
      IMAGE_NAME: '{{.DOCKER_IMAGE_NAME}}'
      IMAGE_TAG: '{{.DOCKER_IMAGE_TAG}}'
    cmds:
      - docker bake dev --progress=tty

  image:build:minimal:
    desc: 'Build minimal image for CI/Jobs'
    env:
      IMAGE_NAME: '{{.DOCKER_IMAGE_NAME}}'
      IMAGE_TAG: '{{.DOCKER_IMAGE_TAG_MINIMAL}}'
    cmds:
      - docker bake minimal --progress=tty

  image:release:
    desc: 'Build and push full image to Registry'
    env:
      IMAGE_NAME: '{{.DOCKER_IMAGE_NAME}}'
      IMAGE_TAG: '{{.DOCKER_IMAGE_TAG}}'
    cmds:
      - docker bake release --progress=tty

  image:release:minimal:
    desc: 'Build and push minimal image to Registry'
    env:
      IMAGE_NAME: '{{.DOCKER_IMAGE_NAME}}'
      IMAGE_TAG: '{{.DOCKER_IMAGE_TAG_MINIMAL}}'
    cmds:
      - docker bake release-minimal --progress=tty

  image:release:all:
    desc: 'Build and push both full and minimal images'
    cmds:
      - task: image:release:minimal
      - task: image:release

  ################################################################################
  # LINTING, VALIDATION & SECURITY TASKS
  ################################################################################

  check:
    desc: 'Run all checks (lint, validation, security)'
    cmds:
      - task: cleanup
      - task: lint
      - task: validate
      - task: security

  # LINTING
  # ------------------------------------------------------------------------------
  lint:
    desc: 'Run all linters'
    cmds:
      - task: lint:yaml
      - task: lint:shell
      - task: lint:dockerfile
      - task: lint:markdown
      - task: lint:helm
      # Uncomment to start using Conventional Commits -> https://www.conventionalcommits.org
      #- task: lint:commit

  lint:yaml:
    desc: 'Lint all YAML files'
    cmds:
      - yamllint .

  lint:shell:
    desc: 'Lint all shell scripts'
    cmds:
      - find . -name '*.sh' -type f | grep -v '/.devbox/' | xargs -r shellcheck

  lint:dockerfile:
    desc: 'Lint all Dockerfiles'
    cmds:
      - find . -name Dockerfile -exec hadolint {} +

  lint:markdown:
    desc: 'Lint all Markdown files'
    cmds:
      - markdownlint-cli2 .

  lint:helm:
    desc: 'Validate Helm values documentation completeness'
    cmds:
      - ./scripts/helm-docs-lint.sh

  lint:commit:
    desc: 'Lint the last commit message'
    cmds:
      - commitlint-rs from HEAD~1

  # VALIDATION
  # ------------------------------------------------------------------------------
  validate:
    desc: 'Run all validation tasks'
    cmds:
      - task: validate:kubeval

  validate:kustomize:
    desc: 'Validate all Kustomize overlays by building them (run validate:kubeval instead for complete validation)'
    cmds:
      - defer: find . -type d -name charts -exec rm -rf {} +
      - for dir in $(find . -type f -name kustomization.yaml -printf '%h\n'); do
        kustomize build $dir --enable-helm > /dev/null; done

  validate:kubeval:
    desc: 'Validate Kubernetes manifests - build Kustomize overlays and check schemas'
    cmds:
      - defer: find . -type d -name charts -exec rm -rf {} +
      - |
        echo "Validating Kustomize overlays and Kubernetes schemas..."
        for dir in $(find . -type f -name kustomization.yaml -printf '%h\n'); do
          echo "  Building and validating: $dir"
          kustomize build $dir --enable-helm | kubeval --ignore-missing-schemas -
        done

  # SECURITY
  # ------------------------------------------------------------------------------
  security:
    desc: 'Run all security scanners'
    cmds:
      - task: security:iac
      - task: security:secrets

  security:iac:
    desc: 'Scan Infrastructure as Code for misconfigurations'
    cmds:
      - checkov --directory . --quiet

  security:secrets:
    desc: 'Scan for hardcoded secrets'
    cmds:
      - trufflehog filesystem . --exclude-paths .trufflehog-ignore --log-level=-1

  cleanup:
    desc: 'Remove temporary chart directories'
    cmds:
      - find . -type d -name charts -exec rm -rf {} +

  # DOCS
  # ------------------------------------------------------------------------------
  docs:
    desc: 'Generate all automatic documentation'
    cmds:
      - task: docs:metadata
      - task: docs:helm

  docs:metadata:
    desc: 'Generate Chart.yaml metadata files for all components'
    cmds:
      - ./scripts/generate-chart-metadata.sh

  docs:helm:
    desc: 'Generate component documentation from Helm values using helm-docs'
    cmds:
      - ./scripts/helm-docs-generate.sh

  docs:build:
    desc: 'Build MkDocs documentation site'
    cmds:
      - mkdocs build --strict

  docs:serve:
    desc: 'Serve documentation locally at http://localhost:8000'
    cmds:
      - mkdocs serve

  docs:deploy:
    desc: 'Deploy documentation to GitHub Pages'
    cmds:
      - mkdocs gh-deploy --force

  docs:linkcheck:
    desc: 'Check for broken links in built documentation'
    cmds:
      - |
        if ! command -v lychee &> /dev/null; then
          echo "âš ï¸  lychee not found, skipping link check"
          exit 0
        fi
        lychee --verbose --no-progress --max-redirects 10 \
          --exclude "localhost|127.0.0.1|0.0.0.0" \
          --exclude "nip.io" \
          site/

  docs:clean:
    desc: 'Clean generated documentation artifacts'
    cmds:
      - rm -rf site/
      - find docs/components -type f -name "index.md" -delete
      - echo "âœ… Documentation artifacts cleaned"

  # CA CERTIFICATE
  # ------------------------------------------------------------------------------
  ca:export:
    desc: 'Export CA certificate for browser import (optional)'
    cmds:
      - |
        kubectl get secret idp-demo-ca-secret -n cert-manager \
          -o jsonpath='{.data.tls\.crt}' | base64 -d > $HOME/idp-demo-ca.crt
        echo "âœ… CA exported to: $HOME/idp-demo-ca.crt"
        echo "   Import in browser to remove security warnings"

  # REGISTRY MANAGEMENT
  # ------------------------------------------------------------------------------
  registry:clean:
    desc: 'Remove registry cache data'
    cmds:
      - rm -rf {{.REGISTRY_CACHE_PATH}}
      - echo "âœ… Registry cache cleaned"

  registry:info:
    desc: 'Show registry status and cache size'
    cmds:
      - |
        if docker ps --filter "name=k3d-registry.localhost" --format "{{.Names}}" | grep -q registry;
        then
          echo "âœ… Registry container running"
          if [ -d "{{.REGISTRY_CACHE_PATH}}" ]; then
            echo "ğŸ“¦ Cache size: $(du -sh {{.REGISTRY_CACHE_PATH}} 2>/dev/null | cut -f1)"
          else
            echo "ğŸ“¦ Cache size: empty"
          fi
          echo "ğŸ“‚ Location: {{.REGISTRY_CACHE_PATH}}"
          echo "ğŸ”— Endpoint: localhost:5000"
        else
          echo "âš ï¸  Registry not running (using config: {{.K3D_CONFIG}})"
        fi
