# @section -- CRDs
# -- Disables the installation of CRDs, as they are managed separately.
crds:
  enabled: false

# @section -- Default Rules
# -- Enable default Prometheus rules for baseline monitoring
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: false # External etcd or k3d specific
    configReloaders: true
    general: true
    k8s: true
    kubeApiserver: true
    kubeApiserverAvailability: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: false # Disabled in exporters section
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: false # Disabled in exporters section
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

# @section -- Alertmanager
alertmanager:
  # -- Enable Alertmanager for alert routing (required for Pyrra burn-rate alerts)
  enabled: true
  alertmanagerSpec:
    # -- (string) Priority class for Alertmanager pod
    priorityClassName: platform-observability
    # -- (string) Alertmanager log format
    logFormat: json
    resources:
      requests:
        # -- (string) CPU request
        cpu: 25m
        # -- (string) Memory request
        memory: 64Mi
      limits:
        # -- (string) CPU limit
        cpu: 100m
        # -- (string) Memory limit
        memory: 128Mi
  # -- Alertmanager configuration
  config:
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'argo-events-webhook'
    receivers:
      - name: 'null'
      - name: 'argo-events-webhook'
        webhook_configs:
          - url: 'http://alertmanager-eventsource-svc.argo-events.svc.cluster.local:12000/webhook'
            send_resolved: true

# @section -- Exporters
# -- Disables because it doesnt exist in k3s.
kubeEtcd:
  enabled: false
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
# -- Disables unnecessary components (Windows nodes not present in k3d demo)
windowsMonitoring:
  enabled: false


# @section -- Prometheus
prometheus:
  prometheusSpec:
    priorityClassName: platform-observability
    # -- Disable default behavior of adding release label when selector is empty
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    # -- Select all ServiceMonitors across all namespaces
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    # -- Select all PodMonitors across all namespaces
    podMonitorSelector: {}
    podMonitorNamespaceSelector: {}
    # -- Select PrometheusRules from any namespace (needed for Pyrra rules)
    ruleSelector: {}
    ruleNamespaceSelector: {}
    # -- External labels to identify the cluster (Required for some imported dashboards like StarsL_en_K8S)
    externalLabels:
      origin_prometheus: "idp-demo-cluster"
    # -- Global scrape interval for all ServiceMonitors (unless overridden).
    scrapeInterval: 60s
    # -- Global scrape timeout for all ServiceMonitors (unless overridden).
    scrapeTimeout: 40s
    # -- Metrics retention time.
    retention: 24h
    # -- Log format for Prometheus (logfmt or json)
    logFormat: json
    # -- Enable persistence for Prometheus TSDB. 1Gi supports 6h retention for ~50 pods
    # with 4x overhead margin. Data survives pod restarts but is lost on cluster destruction.
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
    resources:
      requests:
        # -- (string) CPU request
        cpu: 200m
        # -- (string) Memory request
        memory: 512Mi
      limits:
        # -- (string) CPU limit
        cpu: 500m
        # -- (string) Memory limit
        memory: 1536Mi
    additionalScrapeConfigs:
      - job_name: 'kube-scheduler'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_node_label_node_role_kubernetes_io_control_plane]
            regex: true
            action: keep
          - source_labels: [__meta_kubernetes_node_address_InternalIP]
            replacement: $1:10259
            target_label: __address__
          - source_labels: [__meta_kubernetes_node_name]
            target_label: instance
      - job_name: 'kube-controller-manager'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_node_label_node_role_kubernetes_io_control_plane]
            regex: true
            action: keep
          - source_labels: [__meta_kubernetes_node_address_InternalIP]
            replacement: $1:10257
            target_label: __address__
          - source_labels: [__meta_kubernetes_node_name]
            target_label: instance
      - job_name: 'kube-proxy'
        kubernetes_sd_configs:
          - role: node
        scheme: http
        # Kube-proxy corre en todos los nodos, no filtramos por control-plane
        relabel_configs:
          - source_labels: [__meta_kubernetes_node_address_InternalIP]
            replacement: $1:10249
            target_label: __address__
          - source_labels: [__meta_kubernetes_node_name]
            target_label: instance

# @section -- Grafana
grafana:
  priorityClassName: platform-dashboards
  # -- Enable persistence for dashboards and settings
  persistence:
    enabled: true
    type: pvc
    size: 1Gi
    accessModes: [ReadWriteOnce]
  # -- Use existing secret for admin credentials from Vault via ESO.
  admin:
    # checkov:skip=CKV_SECRET_6:The existingSecret field is a reference to a secret, not a secret itself.
    existingSecret: grafana-admin-credentials
    userKey: admin-user
    # checkov:skip=CKV_SECRET_6:The passwordKey field is a key name, not a secret.
    passwordKey: admin-password
  resources:
    requests:
      # -- (string) CPU request
      cpu: 50m
      # -- (string) Memory request
      memory: 128Mi
    limits:
      # -- (string) CPU limit
      cpu: 250m
      # -- (string) Memory limit
      memory: 256Mi
  # Datasource file expected by Grafana chart (single file with both DS)
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Loki
          uid: Loki
          type: loki
          access: proxy
          url: http://loki.observability.svc.cluster.local:3100
          isDefault: false
  # -- Automatically install useful plugins on startup.
  plugins:
    - grafana-piechart-panel
    - grafana-polystat-panel
    - marcusolsson-json-datasource
    # - mosaic-plot
    # - bubblechart-panel
  # -- Dashboard providers configuration for dashboards downloaded via gnetId
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
  # -- Declare dashboards to be downloaded and provisioned by the chart
  # Note: Components like external-secrets, policy-reporter, pyrra, and fluent-bit
  # provide their own dashboards via ConfigMaps and are not listed here.
  dashboards:
    default:
      # K8s - Deployment dashboard
      k8s-deployment:
        gnetId: 17685
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # K8s - StatefulSet dashboard
      k8s-statefulset:
        gnetId: 7581
        revision: 1
        datasource:
          - name: DS_KUBERNETES
            value: Prometheus
      # K8s - DaemonSet dashboard
      k8s-daemonset:
        gnetId: 14982
        revision: 1
        datasource:
          - name: datasource
            value: Prometheus
      # K8s - Resource dashboard
      k8s-resource:
        gnetId: 21839
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # K8s - Namespace dashboard
      k8s-namespace:
        gnetId: 15758
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # K8s monitoring - Overview dashboard
      k8s:
        gnetId: 22082
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # Cert-manager monitoring - Overview dashboard
      cert-manager:
        gnetId: 20842
        revision: 3
        datasource:
          - name: datasource
            value: Prometheus
      # ArgoCD monitoring - Official ArgoCD dashboard
      argocd:
        gnetId: 14584
        revision: 1
        datasource:
          - name: datasource
            value: Prometheus
      # Cilium Operator metrics
      cilium-operator:
        gnetId: 17660
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # Kyverno policy monitoring - Official Kyverno dashboard
      kyverno:
        gnetId: 15804
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # Trivy Operator security scanning - Official Trivy dashboard
      trivy-operator:
        gnetId: 17813
        revision: 2
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # Trivy Image Vulnerability Overview - Alternative dashboard
      trivy-image-vulnerability:
        gnetId: 16742
        revision: 1
        datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
      # Loki Kubernetes Logs (ID: 15141)
      loki-kubernetes-logs:
        gnetId: 15141
        revision: 1
        datasource:
          - name: DS_LOKI
            value: Loki
      # Kubernetes Logs from Loki (ID: 18494)
      kubernetes-logs-from-loki:
        gnetId: 18494
        revision: 1
        datasource:
          - name: DS_GRAFANACLOUD-SS3RG3-LOGS
            value: Loki
      # Container Log Dashboard (ID: 16966)
      container-log-dashboard:
        gnetId: 16966
        revision: 1
        datasource:
          - name: DS_LOKI
            value: Loki
      # Loki Logging Volume Analysis
      loki-logging-volume:
        gnetId: 23789
        revision: 1
        datasource:
          - name: DS_LOKI
            value: Loki
      # Logs by Namespace
      logs-by-namespace:
        gnetId: 19566
        revision: 1
        datasource:
          - name: DS_LOKI
            value: Loki
      # Logging Dashboard via Loki v2
      logging-dashboard-v2:
        gnetId: 18042
        revision: 1
        datasource:
          - name: DS_LOKI
            value: Loki


  # -- Sidecar to automatically discover and load dashboards from ConfigMaps.
  defaultDashboardsEnabled: false
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      # -- An empty labelValue searches for the presence of the label, regardless of its value.
      labelValue: ""
      # -- Search in all namespaces for dashboards.
      searchNamespace: ALL
  # -- Advanced Grafana configuration via grafana.ini
  grafana.ini:
    security:
      allow_embedding: true
      cookie_samesite: none
      cookie_secure: true
    log:
      mode: console
    "log.console":
      format: json
    users:
      # -- Disables the user sign-up page.
      allow_sign_up: false
      # -- Set the default UI theme to dark.
      default_theme: dark
    feature_toggles:
      provisioning: true
      kubernetesDashboards: true

# @section -- Prometheus Operator
# -- Resource limits and requests for the Prometheus Operator.
prometheusOperator:
  # -- (string) Priority class
  priorityClassName: platform-observability
  # -- Log format for Prometheus Operator (logfmt or json)
  logFormat: json
  # -- Admission webhooks configuration for PrometheusRules validation
  admissionWebhooks:
    enabled: true
    # -- Prevent transient webhook outages from blocking syncs
    # Valid values: Fail, Ignore, IgnoreOnInstallOnly
    failurePolicy: Ignore
    # -- Use cert-manager to manage webhook certificates instead of Helm hook Jobs
    # This avoids compatibility issues with ArgoCD+Kustomize workflow
    certManager:
      enabled: true
      # -- Reference to the ClusterIssuer that will issue webhook certificates
      issuerRef:
        name: ca-issuer
        kind: ClusterIssuer
    # -- Disable Helm hook-based certificate management (incompatible with ArgoCD+Kustomize)
    patch:
      enabled: false
  resources:
    requests:
      # -- (string) CPU request
      cpu: 25m
      # -- (string) Memory request
      memory: 32Mi
    limits:
      # -- (string) CPU limit
      cpu: 50m
      # -- (string) Memory limit
      memory: 64Mi

# @section -- Kube State Metrics
# -- Resource limits and requests for kube-state-metrics.
kube-state-metrics:
  # -- (string) Priority class
  priorityClassName: platform-observability
  # -- (list) Enable only relevant resource types (whitelist approach)
  extraArgs:
    - --resources=cronjobs,daemonsets,deployments,jobs,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,pods,services,statefulsets,storageclasses

  prometheus:
    monitor:
      # -- (list) Drop high-cardinality labels
      metricRelabelings:
        # Drop uid label
        - action: labeldrop
          regex: "uid"
        # Drop container_id
        - action: labeldrop
          regex: "container_id"
        # Drop image_id
        - action: labeldrop
          regex: "image_id"

  resources:
    requests:
      # -- (string) CPU request
      cpu: 25m
      # -- (string) Memory request
      memory: 64Mi
    limits:
      # -- (string) CPU limit
      cpu: 50m
      # -- (string) Memory limit
      memory: 128Mi

# @section -- Prometheus Node Exporter
# -- Resource limits and requests for the node-exporter.
prometheus-node-exporter:
  # -- (string) Priority class
  priorityClassName: platform-observability
  # -- (list) Minimal collector set optimized for K3d
  extraArgs:
    - --collector.disable-defaults
    - --collector.cpu
    - --collector.cpufreq
    - --collector.meminfo
    - --collector.diskstats
    - --collector.filesystem
    - --collector.netdev
    - --collector.loadavg
    - --collector.pressure
    - --collector.vmstat
    - --collector.stat
    - --collector.uname

  resources:
    requests:
      # -- (string) CPU request
      cpu: 15m
      # -- (string) Memory request
      memory: 24Mi
    limits:
      # -- (string) CPU limit
      cpu: 30m
      # -- (string) Memory limit
      memory: 48Mi
